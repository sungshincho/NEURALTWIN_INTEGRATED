/**
 * aiResponseLogger.ts
 *
 * AI ì‘ë‹µ ë¡œê¹… ìœ í‹¸ë¦¬í‹°
 *
 * ëª©ì :
 * - AI ì‹œë®¬ë ˆì´ì…˜/ìµœì í™” ì‘ë‹µì„ ìë™ìœ¼ë¡œ ê¸°ë¡
 * - íŒŒì¸íŠœë‹ìš© í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
 * - ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì— ì˜í–¥ ì—†ë„ë¡ ì²˜ë¦¬
 */

import { SupabaseClient } from 'https://esm.sh/@supabase/supabase-js@2.89.0';

// ============================================================================
// íƒ€ì… ì •ì˜
// ============================================================================

/**
 * ì‹œë®¬ë ˆì´ì…˜ ìœ í˜•
 */
export type SimulationType =
  | 'layout'           // ë ˆì´ì•„ì›ƒ ìµœì í™”
  | 'flow'             // ë™ì„  ì‹œë®¬ë ˆì´ì…˜
  | 'congestion'       // í˜¼ì¡ë„ ì‹œë®¬ë ˆì´ì…˜
  | 'staffing'         // ì¸ë ¥ ë°°ì¹˜ ìµœì í™” (ğŸ†• generate-optimizationì—ì„œ í†µí•©)
  | 'ultimate'         // Ultimate AI ìµœì í™”
  | 'layout_optimization' // advanced-ai-inference layout (deprecated)
  | 'flow_simulation'  // advanced-ai-inference flow (deprecated)
  | 'zone_analysis'    // ì¡´ ë¶„ì„
  | 'product'          // ìƒí’ˆ ë°°ì¹˜ ìµœì í™”
  | 'furniture'        // ê°€êµ¬ ë°°ì¹˜ ìµœì í™”
  | 'both'             // ê°€êµ¬ + ìƒí’ˆ ìµœì í™”
  // ğŸ†• run-simulation ì‹œë®¬ë ˆì´ì…˜ íƒ€ì…
  | 'traffic_flow'     // íŠ¸ë˜í”½ í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜
  | 'demand_prediction' // ìˆ˜ìš” ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
  // ğŸ†• í”„ë¦¬ì…‹ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ (ë™ì  íƒ€ì…)
  | `scenario_${string}`; // scenario_christmas, scenario_blackFriday ë“±

/**
 * í•¨ìˆ˜ëª…
 */
export type FunctionName =
  | 'generate-optimization'
  | 'advanced-ai-inference'
  | 'retail-ai-inference'
  | 'unified-ai'
  | 'run-simulation';

/**
 * ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° (ì…ë ¥ í¬ê¸° ìš”ì•½)
 */
export interface ContextMetadata {
  furnitureCount?: number;
  productCount?: number;
  zoneCount?: number;
  slotCount?: number;
  transitionCount?: number;
  hasWeatherData?: boolean;
  hasFlowData?: boolean;
  hasAssociationData?: boolean;
  hasVMDData?: boolean;
  associationRulesCount?: number;
  dataQuality?: string;
  [key: string]: unknown;
}

/**
 * ì‘ë‹µ ìš”ì•½ (ë¹ ë¥¸ ì¡°íšŒìš©)
 */
export interface ResponseSummary {
  // ë³€ê²½ ì‚¬í•­
  furnitureChangesCount?: number;
  productChangesCount?: number;
  totalChangesCount?: number;

  // ì˜ˆìƒ íš¨ê³¼
  expectedRevenueIncrease?: number;
  expectedTrafficIncrease?: number;
  expectedConversionIncrease?: number;

  // VMD
  vmdScore?: number;
  vmdGrade?: string;

  // ë™ì„ 
  flowHealthScore?: number;
  bottleneckCount?: number;
  deadZoneCount?: number;

  // ì‹ ë¢°ë„
  confidence?: number;
  overallConfidence?: number;

  // ê¸°íƒ€
  [key: string]: unknown;
}

/**
 * ë¡œê¹… ì…ë ¥ íŒŒë¼ë¯¸í„°
 */
export interface AIResponseLogInput {
  // í•„ìˆ˜ í•„ë“œ
  storeId: string;
  functionName: FunctionName;
  simulationType: SimulationType;
  inputVariables: Record<string, unknown>;
  aiResponse: Record<string, unknown>;

  // ì„ íƒ í•„ë“œ
  userId?: string;
  responseSummary?: ResponseSummary;
  contextMetadata?: ContextMetadata;
  executionTimeMs?: number;
  modelUsed?: string;
  promptTokens?: number;
  completionTokens?: number;

  // ì—ëŸ¬ ì •ë³´
  hadError?: boolean;
  errorMessage?: string;

  // ğŸ†• S0-5: íŒŒì‹± ì„±ê³µë¥  ì¶”ì 
  parseSuccess?: boolean;
  usedFallback?: boolean;
  parseAttempts?: Array<{
    method: string;
    success: boolean;
    error?: string;
  }>;
  rawResponseLength?: number;
}

/**
 * ë¡œê¹… ê²°ê³¼
 */
export interface AIResponseLogResult {
  success: boolean;
  logId?: string;
  error?: string;
}

// ============================================================================
// ë©”ì¸ ë¡œê¹… í•¨ìˆ˜
// ============================================================================

/**
 * AI ì‘ë‹µì„ ë¡œê·¸ í…Œì´ë¸”ì— ì €ì¥
 *
 * @param supabase - Supabase í´ë¼ì´ì–¸íŠ¸ (service_role í‚¤ ì‚¬ìš© ê¶Œì¥)
 * @param input - ë¡œê¹… ì…ë ¥ ë°ì´í„°
 * @returns ë¡œê¹… ê²°ê³¼
 *
 * ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
 * í•­ìƒ try-catchë¡œ ê°ì‹¸ì„œ í˜¸ì¶œí•˜ê±°ë‚˜, ë°˜í™˜ëœ success ê°’ì„ í™•ì¸í•˜ì„¸ìš”.
 */
export async function logAIResponse(
  supabase: SupabaseClient,
  input: AIResponseLogInput
): Promise<AIResponseLogResult> {
  try {
    const {
      storeId,
      functionName,
      simulationType,
      inputVariables,
      aiResponse,
      userId,
      responseSummary,
      contextMetadata,
      executionTimeMs,
      modelUsed,
      promptTokens,
      completionTokens,
      hadError = false,
      errorMessage,
      // ğŸ†• S0-5: íŒŒì‹± ì„±ê³µë¥  ì¶”ì 
      parseSuccess,
      usedFallback,
      parseAttempts,
      rawResponseLength,
    } = input;

    // ì…ë ¥ ê²€ì¦
    if (!storeId || !functionName || !simulationType) {
      return {
        success: false,
        error: 'Missing required fields: storeId, functionName, or simulationType',
      };
    }

    // ë¡œê·¸ ë ˆì½”ë“œ ìƒì„±
    const logRecord = {
      store_id: storeId,
      user_id: userId || null,
      function_name: functionName,
      simulation_type: simulationType,
      input_variables: sanitizeForJsonb(inputVariables),
      ai_response: sanitizeForJsonb(aiResponse),
      response_summary: responseSummary ? sanitizeForJsonb(responseSummary) : {},
      context_metadata: contextMetadata ? sanitizeForJsonb(contextMetadata) : {},
      execution_time_ms: executionTimeMs || null,
      model_used: modelUsed || null,
      prompt_tokens: promptTokens || null,
      completion_tokens: completionTokens || null,
      had_error: hadError,
      error_message: errorMessage || null,
      // ğŸ†• S0-5: íŒŒì‹± ì„±ê³µë¥  ì¶”ì 
      parse_success: parseSuccess ?? !hadError,
      used_fallback: usedFallback ?? false,
      parse_attempts: parseAttempts ? sanitizeForJsonb(parseAttempts) : null,
      raw_response_length: rawResponseLength || null,
    };

    // ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
    const { data, error } = await supabase
      .from('ai_response_logs')
      .insert(logRecord)
      .select('id')
      .single();

    if (error) {
      console.error('[AIResponseLogger] Insert failed:', error.message);
      return {
        success: false,
        error: error.message,
      };
    }

    console.log(`[AIResponseLogger] Logged response: ${data?.id} (${functionName}/${simulationType})`);

    return {
      success: true,
      logId: data?.id,
    };
  } catch (err) {
    const errorMessage = err instanceof Error ? err.message : 'Unknown error';
    console.error('[AIResponseLogger] Exception:', errorMessage);
    return {
      success: false,
      error: errorMessage,
    };
  }
}

// ============================================================================
// ìš”ì•½ ìƒì„± í—¬í¼ í•¨ìˆ˜ë“¤
// ============================================================================

/**
 * generate-optimization ì‘ë‹µì—ì„œ ìš”ì•½ ìƒì„±
 */
export function createOptimizationSummary(result: any): ResponseSummary {
  return {
    furnitureChangesCount: result.furniture_changes?.length || 0,
    productChangesCount: result.product_changes?.length || 0,
    totalChangesCount:
      (result.furniture_changes?.length || 0) + (result.product_changes?.length || 0),
    expectedRevenueIncrease: result.summary?.expected_revenue_improvement,
    expectedTrafficIncrease: result.summary?.expected_traffic_improvement,
    expectedConversionIncrease: result.summary?.expected_conversion_improvement,
    vmdScore: result.vmd_analysis?.score?.overall,
    vmdGrade: result.vmd_analysis?.score?.grade,
    flowHealthScore: result.flow_analysis_summary?.flow_health_score,
    bottleneckCount: result.flow_analysis_summary?.bottleneck_count,
    deadZoneCount: result.flow_analysis_summary?.dead_zone_count,
    confidence: result.prediction_summary?.overall_confidence,
  };
}

/**
 * generate-optimization ì…ë ¥ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ìƒì„±
 */
export function createOptimizationContextMetadata(
  layoutData: any,
  slotsData: any[],
  flowAnalysis?: any,
  associationData?: any,
  environmentData?: any,
  vmdAnalysis?: any
): ContextMetadata {
  return {
    furnitureCount: layoutData?.furniture?.length || 0,
    productCount: layoutData?.products?.length || 0,
    zoneCount: layoutData?.zones?.length || 0,
    slotCount: slotsData?.length || 0,
    transitionCount: flowAnalysis?.summary?.totalTransitions || 0,
    hasWeatherData: !!environmentData?.weather,
    hasFlowData: !!flowAnalysis,
    hasAssociationData: !!associationData,
    hasVMDData: !!vmdAnalysis,
    associationRulesCount: associationData?.summary?.totalRulesFound || 0,
    dataQuality: environmentData?.dataQuality?.overall || 'unknown',
    flowHealthScore: flowAnalysis?.summary?.flowHealthScore,
    vmdScore: vmdAnalysis?.score?.overall,
  };
}

/**
 * advanced-ai-inference ì‘ë‹µì—ì„œ ìš”ì•½ ìƒì„±
 */
export function createInferenceSummary(result: any, simulationType: SimulationType): ResponseSummary {
  const summary: ResponseSummary = {};

  switch (simulationType) {
    case 'layout':
    case 'layout_optimization':
      summary.furnitureChangesCount = result.furnitureMoves?.length || result.layoutChanges?.length || 0;
      summary.productChangesCount = result.productPlacements?.length || 0;
      summary.expectedRevenueIncrease = result.optimizationSummary?.expectedRevenueIncreasePercent;
      summary.confidence = result.confidence;
      break;

    case 'flow':
    case 'flow_simulation':
      summary.bottleneckCount = result.bottlenecks?.length || 0;
      summary.flowHealthScore = result.summary?.flowHealthScore;
      summary.expectedConversionIncrease = result.summary?.conversionRate;
      summary.confidence = result.confidence;
      break;

    case 'congestion':
      summary.bottleneckCount = result.congestionPoints?.length || 0;
      summary.confidence = result.confidence;
      break;

    case 'staffing':
      summary.confidence = result.confidence;
      break;

    default:
      summary.confidence = result.confidence;
  }

  return summary;
}

/**
 * advanced-ai-inference ì…ë ¥ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ìƒì„±
 */
export function createInferenceContextMetadata(
  storeContext: any,
  params: any
): ContextMetadata {
  return {
    furnitureCount: storeContext?.entities?.filter((e: any) => e.type === 'furniture')?.length || 0,
    productCount: storeContext?.entities?.filter((e: any) => e.type === 'product')?.length || 0,
    zoneCount: storeContext?.zones?.length || 0,
    hasFlowData: !!storeContext?.zoneTransitions?.length,
    transitionCount: storeContext?.zoneTransitions?.length || 0,
    dataQuality: storeContext?.dataQuality?.overallScore?.toString() || 'unknown',
    salesDataDays: storeContext?.dataQuality?.salesDataDays,
    visitorDataDays: storeContext?.dataQuality?.visitorDataDays,
    hasZoneData: storeContext?.dataQuality?.hasZoneData,
    analysisDepth: params?.analysisDepth,
    customerCount: params?.customerCount,
    duration: params?.duration,
  };
}

// ============================================================================
// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
// ============================================================================

/**
 * JSONB ì €ì¥ì„ ìœ„í•´ ê°ì²´ë¥¼ ì •ë¦¬
 * - undefined ê°’ ì œê±°
 * - ìˆœí™˜ ì°¸ì¡° ë°©ì§€
 * - í° ë°ì´í„° ì œí•œ
 */
function sanitizeForJsonb(obj: unknown, maxDepth = 10): unknown {
  if (maxDepth <= 0) {
    return '[Max depth exceeded]';
  }

  if (obj === null || obj === undefined) {
    return null;
  }

  if (typeof obj !== 'object') {
    // ë¬¸ìì—´ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
    if (typeof obj === 'string' && obj.length > 10000) {
      return obj.substring(0, 10000) + '... [truncated]';
    }
    return obj;
  }

  if (Array.isArray(obj)) {
    // ë°°ì—´ì´ ë„ˆë¬´ í¬ë©´ ì¼ë¶€ë§Œ ì €ì¥
    const maxArrayLength = 100;
    const truncated = obj.length > maxArrayLength;
    const sliced = obj.slice(0, maxArrayLength);
    const result = sliced.map(item => sanitizeForJsonb(item, maxDepth - 1));
    if (truncated) {
      result.push(`[... ${obj.length - maxArrayLength} more items]`);
    }
    return result;
  }

  // ê°ì²´ ì²˜ë¦¬
  const result: Record<string, unknown> = {};
  for (const [key, value] of Object.entries(obj)) {
    if (value !== undefined) {
      result[key] = sanitizeForJsonb(value, maxDepth - 1);
    }
  }
  return result;
}

/**
 * ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í—¬í¼
 */
export function createExecutionTimer(): {
  start: () => void;
  getElapsedMs: () => number;
} {
  let startTime: number;

  return {
    start: () => {
      startTime = performance.now();
    },
    getElapsedMs: () => {
      return Math.round(performance.now() - startTime);
    },
  };
}

/**
 * ë¹„ë™ê¸° ë¡œê¹… (ë©”ì¸ ì‘ë‹µ ë°˜í™˜ í›„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
 *
 * ì£¼ì˜: Deno Deployì—ì„œëŠ” ì‘ë‹µ ë°˜í™˜ í›„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì´
 * ì¦‰ì‹œ ì¢…ë£Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ ë™ê¸°ì ìœ¼ë¡œ ë¡œê¹…í•˜ì„¸ìš”.
 */
export function logAIResponseAsync(
  supabase: SupabaseClient,
  input: AIResponseLogInput
): void {
  // Fire-and-forget ë°©ì‹
  logAIResponse(supabase, input).catch(err => {
    console.error('[AIResponseLogger] Async logging failed:', err);
  });
}

// ============================================================================
// ğŸ†• S0-5: íŒŒì‹± ì„±ê³µë¥  í†µê³„ ì¡°íšŒ í•¨ìˆ˜
// ============================================================================

/**
 * íŒŒì‹± ì„±ê³µë¥  í†µê³„ ì¡°íšŒ ê²°ê³¼
 */
export interface ParseSuccessStats {
  total: number;
  success: number;
  failure: number;
  fallback: number;
  successRate: number;
  fallbackRate: number;
  avgResponseTime: number;
}

/**
 * í•¨ìˆ˜ë³„ íŒŒì‹± ì„±ê³µë¥  í†µê³„ ì¡°íšŒ
 */
export async function getParseSuccessStats(
  supabase: SupabaseClient,
  options?: {
    functionName?: FunctionName;
    storeId?: string;
    since?: Date;
    limit?: number;
  }
): Promise<ParseSuccessStats> {
  try {
    let query = supabase
      .from('ai_response_logs')
      .select('parse_success, used_fallback, execution_time_ms');

    if (options?.functionName) {
      query = query.eq('function_name', options.functionName);
    }
    if (options?.storeId) {
      query = query.eq('store_id', options.storeId);
    }
    if (options?.since) {
      query = query.gte('created_at', options.since.toISOString());
    }
    if (options?.limit) {
      query = query.limit(options.limit);
    }

    const { data, error } = await query;

    if (error || !data) {
      console.error('[AIResponseLogger] Stats query failed:', error?.message);
      return {
        total: 0,
        success: 0,
        failure: 0,
        fallback: 0,
        successRate: 0,
        fallbackRate: 0,
        avgResponseTime: 0,
      };
    }

    const total = data.length;
    const success = data.filter(d => d.parse_success && !d.used_fallback).length;
    const failure = data.filter(d => !d.parse_success && !d.used_fallback).length;
    const fallback = data.filter(d => d.used_fallback).length;
    const avgResponseTime = total > 0
      ? data.reduce((sum, d) => sum + (d.execution_time_ms || 0), 0) / total
      : 0;

    return {
      total,
      success,
      failure,
      fallback,
      successRate: total > 0 ? (success / total) * 100 : 0,
      fallbackRate: total > 0 ? (fallback / total) * 100 : 0,
      avgResponseTime: Math.round(avgResponseTime),
    };
  } catch (err) {
    console.error('[AIResponseLogger] Stats exception:', err);
    return {
      total: 0,
      success: 0,
      failure: 0,
      fallback: 0,
      successRate: 0,
      fallbackRate: 0,
      avgResponseTime: 0,
    };
  }
}

/**
 * í•¨ìˆ˜ë³„ ì„±ê³µë¥  ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ
 */
export async function getSuccessRateDashboard(
  supabase: SupabaseClient,
  since?: Date
): Promise<Array<{
  functionName: FunctionName;
  total: number;
  successRate: number;
  fallbackRate: number;
  avgResponseTime: number;
  lastError?: string;
}>> {
  try {
    let query = supabase
      .from('ai_response_logs')
      .select('function_name, parse_success, used_fallback, execution_time_ms, error_message, created_at')
      .order('created_at', { ascending: false });

    if (since) {
      query = query.gte('created_at', since.toISOString());
    }

    const { data, error } = await query;

    if (error || !data) {
      console.error('[AIResponseLogger] Dashboard query failed:', error?.message);
      return [];
    }

    // í•¨ìˆ˜ë³„ë¡œ ê·¸ë£¹í™”
    const grouped = data.reduce((acc, row) => {
      const fn = row.function_name as FunctionName;
      if (!acc[fn]) {
        acc[fn] = { total: 0, success: 0, fallback: 0, totalTime: 0, lastError: undefined };
      }
      acc[fn].total++;
      if (row.parse_success && !row.used_fallback) acc[fn].success++;
      if (row.used_fallback) acc[fn].fallback++;
      acc[fn].totalTime += row.execution_time_ms || 0;
      if (row.error_message && !acc[fn].lastError) {
        acc[fn].lastError = row.error_message;
      }
      return acc;
    }, {} as Record<FunctionName, {
      total: number;
      success: number;
      fallback: number;
      totalTime: number;
      lastError?: string;
    }>);

    return Object.entries(grouped).map(([functionName, stats]) => ({
      functionName: functionName as FunctionName,
      total: stats.total,
      successRate: stats.total > 0 ? Math.round((stats.success / stats.total) * 100) : 0,
      fallbackRate: stats.total > 0 ? Math.round((stats.fallback / stats.total) * 100) : 0,
      avgResponseTime: stats.total > 0 ? Math.round(stats.totalTime / stats.total) : 0,
      lastError: stats.lastError,
    }));
  } catch (err) {
    console.error('[AIResponseLogger] Dashboard exception:', err);
    return [];
  }
}

/**
 * safeJsonParse ê²°ê³¼ì—ì„œ ë¡œê¹… ë°ì´í„° ì¶”ì¶œ
 */
export function extractParseResultForLogging<T>(
  parseResult: {
    success: boolean;
    data: T;
    error?: string;
    rawResponse?: string;
    parseAttempts?: Array<{ method: string; success: boolean; error?: string }>;
  }
): {
  parseSuccess: boolean;
  usedFallback: boolean;
  parseAttempts?: Array<{ method: string; success: boolean; error?: string }>;
  rawResponseLength?: number;
  errorMessage?: string;
} {
  const isFallback = !!(parseResult.data as any)?._fallback;

  return {
    parseSuccess: parseResult.success && !isFallback,
    usedFallback: isFallback,
    parseAttempts: parseResult.parseAttempts,
    rawResponseLength: parseResult.rawResponse?.length,
    errorMessage: parseResult.error,
  };
}

// ============================================================================
// Export
// ============================================================================

export default {
  logAIResponse,
  logAIResponseAsync,
  createOptimizationSummary,
  createOptimizationContextMetadata,
  createInferenceSummary,
  createInferenceContextMetadata,
  createExecutionTimer,
  // ğŸ†• S0-5
  getParseSuccessStats,
  getSuccessRateDashboard,
  extractParseResultForLogging,
};
