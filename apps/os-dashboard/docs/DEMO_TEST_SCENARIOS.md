# NEURALTWIN 데모 테스트 시나리오

> 최종 업데이트: 2025-11-17

## 목차
1. [기본 시나리오](#1-기본-시나리오)
2. [고급 시나리오](#2-고급-시나리오)
3. [통합 시나리오](#3-통합-시나리오)
4. [성능 테스트 시나리오](#4-성능-테스트-시나리오)
5. [장애 복구 시나리오](#5-장애-복구-시나리오)

---

## 1. 기본 시나리오

### 시나리오 1.1: 신규 사용자 온보딩
**목표**: 신규 사용자가 첫 매장을 등록하고 데이터를 업로드하는 과정 검증

#### 단계별 절차
1. **회원가입 및 로그인**
   - 이메일/비밀번호로 회원가입
   - 자동 로그인 확인
   - 대시보드 진입

2. **첫 매장 등록**
   - `/stores` 페이지 이동
   - "매장 추가" 버튼 클릭
   - 매장 정보 입력:
     - 매장명: "강남점"
     - 매장 코드: "GN001"
     - 주소: "서울 강남구 테헤란로 123"
     - 담당자: "김매니저"
     - 연락처: "02-1234-5678"
   - 저장 및 확인

3. **샘플 데이터 다운로드**
   - `/data-import` 페이지 이동
   - "샘플 데이터 다운로드" 클릭
   - 5개 CSV 파일 확인 (customers, products, purchases, visits, staff)

4. **데이터 임포트**
   - CSV 파일 업로드 (드래그 앤 드롭)
   - 자동 스키마 분류 확인
   - 데이터 미리보기 확인
   - "저장" 버튼 클릭
   - 임포트 완료 메시지 확인

#### 예상 결과
- ✅ 매장이 데이터베이스에 저장됨
- ✅ 5개 CSV 파일이 Storage에 저장됨
- ✅ `user_data_imports` 테이블에 이력 기록
- ✅ 사이드바에서 매장 선택 가능

#### 검증 포인트
- [ ] 회원가입 후 자동 로그인
- [ ] 매장 등록 후 목록에 표시
- [ ] CSV 파일 업로드 성공
- [ ] 데이터 미리보기 정상 표시
- [ ] Storage에 파일 저장 확인

---

### 시나리오 1.2: 3D 매장 모델 업로드 및 시각화
**목표**: 3D 모델을 업로드하고 디지털 트윈에서 확인

#### 단계별 절차
1. **3D 모델 준비**
   - 파일명 규칙 준수: `Store_강남점_20.0x10.0x4.0.glb`
   - 파일 크기: 5MB 이하
   - 형식: GLB

2. **모델 업로드**
   - `/digital-twin/setup-3d-data` 페이지 이동
   - "3D 모델 업로드" 섹션
   - 파일 선택 또는 드래그 앤 드롭
   - 업로드 진행률 확인

3. **자동 매핑 확인**
   - 파일명 파싱 결과 확인:
     - Entity Type: Store
     - Identifier: 강남점
     - Dimensions: 20.0 x 10.0 x 4.0m
   - 온톨로지 엔티티 생성 확인

4. **3D 뷰어에서 확인**
   - `/digital-twin/3d` 페이지 이동
   - 3D 모델 로딩 확인
   - OrbitControls로 회전/줌 테스트
   - 조명 및 그리드 표시 확인

#### 예상 결과
- ✅ 3D 모델이 Storage에 저장됨
- ✅ `ontology_entity_types` 테이블에 Store 타입 생성
- ✅ `graph_entities` 테이블에 강남점 엔티티 생성
- ✅ 3D 뷰어에서 모델 렌더링

#### 검증 포인트
- [ ] GLB 파일 업로드 성공
- [ ] 파일명 파싱 정확도
- [ ] 온톨로지 엔티티 생성
- [ ] 3D 렌더링 정상 작동
- [ ] 컨트롤 반응성 확인

---

### 시나리오 1.3: 고객 동선 히트맵 확인
**목표**: 업로드한 방문 데이터를 히트맵으로 시각화

#### 단계별 절차
1. **방문 데이터 확인**
   - `/data-import` 페이지에서 visits.csv 확인
   - 최소 100건 이상의 방문 데이터 필요
   - 좌표 데이터 (x, z) 포함 확인

2. **히트맵 페이지 이동**
   - `/footfall/traffic-heatmap` 페이지 이동
   - 매장 선택 (강남점)
   - 날짜 범위 설정 (최근 7일)

3. **히트맵 시각화 확인**
   - 2D 히트맵 표시 확인
   - 색상 그라디언트 (파랑 → 빨강)
   - 고밀도 영역 식별
   - 저밀도 영역 식별

4. **필터링 테스트**
   - 시간대 필터 (오전/오후)
   - 요일 필터 (평일/주말)
   - 카테고리 필터 (있는 경우)

#### 예상 결과
- ✅ 히트맵이 정상 표시됨
- ✅ 고밀도 영역이 빨간색으로 표시
- ✅ 저밀도 영역이 파란색으로 표시
- ✅ 필터 적용 시 실시간 업데이트

#### 검증 포인트
- [ ] 히트맵 렌더링 속도 (1초 이내)
- [ ] 색상 그라디언트 정확도
- [ ] 필터 적용 반응성
- [ ] 데이터 포인트 정확도
- [ ] 빈 데이터 처리

---

## 2. 고급 시나리오

### 시나리오 2.1: 온톨로지 기반 매장 구성
**목표**: 온톨로지를 사용하여 매장 구조를 그래프로 모델링

#### 단계별 절차
1. **엔티티 타입 정의**
   - `/ontology/schema-builder` 페이지 이동
   - Store, Shelf, Product, Zone 타입 생성
   - 각 타입에 속성 정의:
     - Store: name, area, location
     - Shelf: name, capacity, zone
     - Product: name, price, category
     - Zone: name, coordinates

2. **관계 타입 정의**
   - Store -[contains]-> Zone
   - Zone -[has]-> Shelf
   - Shelf -[displays]-> Product
   - Product -[belongs_to]-> Brand

3. **3D 모델 연결**
   - 각 엔티티 타입에 3D 모델 URL 매핑
   - Shelf: `Shelf_메인진열대_3.0x2.0x0.5.glb`
   - Product: `Product_청바지_0.3x0.4x0.1.glb`

4. **엔티티 인스턴스 생성**
   - Store 엔티티: "강남점"
   - Zone 엔티티: "입구", "의류구역", "계산대"
   - Shelf 엔티티: "메인진열대1", "메인진열대2"
   - Product 엔티티: CSV 데이터 자동 매핑

5. **관계 생성**
   - 강남점 -[contains]-> 입구
   - 의류구역 -[has]-> 메인진열대1
   - 메인진열대1 -[displays]-> 청바지

6. **그래프 시각화**
   - `/ontology/graph-analysis` 페이지 이동
   - Force Graph 2D로 전체 구조 확인
   - 노드 클릭하여 상세 정보 확인

#### 예상 결과
- ✅ 엔티티 타입 5개 생성
- ✅ 관계 타입 4개 생성
- ✅ 엔티티 인스턴스 50개 이상
- ✅ 관계 100개 이상
- ✅ 그래프 시각화 정상 표시

#### 검증 포인트
- [ ] 엔티티 타입 생성 및 수정
- [ ] 관계 타입 방향성 설정
- [ ] 3D 모델 URL 매핑
- [ ] 그래프 쿼리 성능
- [ ] 시각화 반응성

---

### 시나리오 2.2: WiFi 트래킹 데모
**목표**: WiFi 센서 데이터를 사용하여 실시간 고객 위치 추적

#### 단계별 절차
1. **WiFi 센서 등록**
   - `/neuralsense-settings` 페이지 이동
   - "센서 등록" 클릭
   - 센서 정보 입력:
     - Device ID: NS001
     - Device Name: 입구센서
     - Location: (0, 0, 2.5)
   - 추가 센서 2개 등록 (NS002, NS003)

2. **Raw Signal 데이터 업로드**
   - `/data-import` 페이지에서 "WiFi 데이터 관리" 탭
   - `wifi_raw_signals.csv` 업로드:
     - 컬럼: mac_address, sensor_id, rssi, timestamp
     - 최소 1000건 데이터
   - 업로드 완료 확인

3. **위치 추정 실행**
   - Trilateration 알고리즘 자동 실행
   - `wifi_tracking` 테이블에 좌표 저장 확인
   - 정확도 메타데이터 확인

4. **3D 오버레이 확인**
   - `/digital-twin/wifi-tracking-demo` 페이지 이동
   - WiFi 트래킹 오버레이 활성화
   - 실시간 고객 아바타 표시 확인
   - 이동 경로 애니메이션 확인

5. **히트맵 캐시 생성**
   - 시간대별 히트맵 캐시 자동 생성
   - `wifi_heatmap_cache` 테이블 확인
   - 히트맵 렌더링 속도 개선 확인

#### 예상 결과
- ✅ WiFi 센서 3개 등록
- ✅ Raw Signal 1000건 업로드
- ✅ 위치 추정 성공률 90% 이상
- ✅ 3D 오버레이 실시간 업데이트
- ✅ 히트맵 캐시 생성

#### 검증 포인트
- [ ] 센서 등록 및 관리
- [ ] Raw Signal 데이터 파싱
- [ ] Trilateration 정확도
- [ ] 3D 아바타 렌더링
- [ ] 히트맵 캐시 성능

---

### 시나리오 2.3: AI 기반 레이아웃 시뮬레이션
**목표**: AI를 활용하여 최적 매장 레이아웃 추천

#### 단계별 절차
1. **기존 레이아웃 데이터 준비**
   - visits.csv: 고객 동선 데이터
   - purchases.csv: 구매 데이터
   - products.csv: 상품 위치 데이터

2. **레이아웃 시뮬레이터 실행**
   - `/profit-center/layout-simulator` 페이지 이동
   - "AI 레이아웃 시뮬레이션" 버튼 클릭
   - 분석 진행 상태 확인

3. **AI 분석 요청**
   - Edge Function 호출: `advanced-ai-inference`
   - 입력 데이터:
     - 현재 레이아웃
     - 고객 동선 패턴
     - 구매 전환율
     - 체류 시간 분포

4. **추천 결과 확인**
   - 최적 레이아웃 제안 (3가지)
   - 각 레이아웃의 예상 효과:
     - 전환율 증가율
     - 체류 시간 변화
     - 매출 증가 예상액
   - 3D 프리뷰로 시각화

5. **비교 분석**
   - 현재 vs 추천 레이아웃 비교
   - 히트맵 오버레이 비교
   - 동선 효율성 점수 비교

#### 예상 결과
- ✅ AI 분석 완료 (30초 이내)
- ✅ 3가지 레이아웃 추천
- ✅ 예상 효과 수치 제공
- ✅ 3D 시뮬레이션 표시
- ✅ 비교 차트 생성

#### 검증 포인트
- [ ] AI 모델 응답 시간
- [ ] 추천 정확도
- [ ] 3D 시뮬레이션 품질
- [ ] 비교 차트 정확도
- [ ] 사용자 피드백 저장

---

## 3. 통합 시나리오

### 시나리오 3.1: 엔드투엔드 매장 분석 워크플로우
**목표**: 데이터 임포트부터 AI 인사이트까지 전체 프로세스 검증

#### 단계별 절차 (30분 소요)

**Phase 1: 데이터 준비 (5분)**
1. 신규 매장 "홍대점" 등록
2. 5개 CSV 파일 임포트
3. 3D 매장 모델 업로드
4. WiFi 센서 3개 등록

**Phase 2: 온톨로지 구축 (5분)**
1. 엔티티 타입 정의 (Store, Zone, Shelf, Product)
2. 관계 타입 정의
3. CSV 데이터 자동 매핑
4. 그래프 생성 및 확인

**Phase 3: 3D 디지털 트윈 구성 (5분)**
1. Scene Composer에서 Zone 배치
2. Shelf 3D 모델 배치
3. Product 3D 모델 배치
4. 조명 및 카메라 설정

**Phase 4: 분석 실행 (10분)**
1. 트래픽 히트맵 생성
2. 전환 퍼널 분석
3. 고객 여정 분석
4. 상품 성과 분석
5. 직원 효율성 분석

**Phase 5: AI 인사이트 생성 (5분)**
1. AI 분석 버튼 클릭 (각 분석 페이지)
2. 인사이트 대시보드 확인
3. 추천 사항 리뷰
4. 알림 설정
5. 리포트 생성 및 다운로드

#### 예상 결과
- ✅ 완전한 디지털 트윈 구축
- ✅ 5가지 분석 완료
- ✅ 20개 이상의 AI 인사이트
- ✅ 3가지 추천 사항
- ✅ PDF 리포트 생성

#### 검증 포인트
- [ ] 전체 워크플로우 완료 시간
- [ ] 각 단계 데이터 정합성
- [ ] AI 인사이트 품질
- [ ] 3D 시각화 일관성
- [ ] 리포트 완성도

---

### 시나리오 3.2: 멀티 스토어 비교 분석
**목표**: 여러 매장의 데이터를 비교하여 인사이트 도출

#### 단계별 절차
1. **3개 매장 준비**
   - 강남점, 홍대점, 신촌점
   - 각 매장 데이터 임포트
   - 동일한 기간 데이터 (최근 30일)

2. **매장 간 비교 분석**
   - `/analytics` 페이지 이동
   - "비교 분석" 탭 선택
   - 3개 매장 선택
   - 비교 지표:
     - 일평균 방문객 수
     - 평균 체류 시간
     - 전환율
     - 객단가
     - 매출

3. **성과 순위 확인**
   - 각 지표별 매장 순위
   - 최고/최저 성과 매장 식별
   - 차이 원인 분석 (AI 인사이트)

4. **Best Practice 도출**
   - 최고 성과 매장의 특징 분석
   - 레이아웃 패턴 비교
   - 상품 배치 전략 비교
   - 직원 운영 방식 비교

5. **개선 제안**
   - 저성과 매장에 대한 구체적 제안
   - 벤치마크 목표 설정
   - 실행 계획 생성

#### 예상 결과
- ✅ 3개 매장 데이터 비교
- ✅ 5가지 지표 순위
- ✅ 성과 차이 원인 분석
- ✅ Best Practice 3가지
- ✅ 개선 제안 5가지

#### 검증 포인트
- [ ] 멀티 스토어 데이터 로딩
- [ ] 비교 차트 정확도
- [ ] AI 원인 분석 품질
- [ ] Best Practice 도출
- [ ] 실행 가능한 제안

---

## 4. 성능 테스트 시나리오

### 시나리오 4.1: 대용량 데이터 처리
**목표**: 대량의 데이터를 처리할 수 있는지 검증

#### 테스트 케이스
1. **대용량 CSV 임포트**
   - visits.csv: 100,000건
   - purchases.csv: 50,000건
   - 임포트 시간 측정
   - 메모리 사용량 모니터링

2. **히트맵 렌더링 성능**
   - 10,000개 데이터 포인트
   - 렌더링 시간 < 2초
   - 줌/팬 반응성 확인

3. **그래프 쿼리 성능**
   - 10,000개 노드
   - 50,000개 엣지
   - N-hop 쿼리 (3-hop) < 1초

4. **3D 모델 로딩 성능**
   - 50개 3D 모델 동시 로딩
   - 총 로딩 시간 < 10초
   - FPS > 30

#### 성능 목표
- ✅ CSV 임포트: 1000건/초
- ✅ 히트맵 렌더링: < 2초
- ✅ 그래프 쿼리: < 1초
- ✅ 3D 로딩: < 10초
- ✅ 메모리: < 500MB

#### 검증 포인트
- [ ] 임포트 처리 속도
- [ ] 렌더링 프레임율
- [ ] 쿼리 응답 시간
- [ ] 메모리 누수 없음
- [ ] CPU 사용률 < 80%

---

### 시나리오 4.2: 동시 사용자 테스트
**목표**: 여러 사용자가 동시에 사용할 때 안정성 검증

#### 테스트 케이스
1. **10명 동시 접속**
   - 각자 다른 매장 데이터 조회
   - 동시 데이터 임포트
   - 동시 AI 분석 요청

2. **RLS 정책 검증**
   - 사용자 A는 사용자 B의 데이터 접근 불가
   - 매장 데이터 격리 확인
   - 분석 이력 격리 확인

3. **Realtime 동기화**
   - 사용자 A가 데이터 추가
   - 사용자 B는 실시간 업데이트 확인 (같은 매장)
   - 다른 매장 사용자는 업데이트 안 받음

#### 성능 목표
- ✅ 동시 접속: 100명
- ✅ 응답 시간: < 3초
- ✅ RLS 정책: 100% 격리
- ✅ Realtime 지연: < 500ms

#### 검증 포인트
- [ ] 동시 접속 안정성
- [ ] 데이터 격리 확인
- [ ] Realtime 동기화
- [ ] 서버 부하 모니터링
- [ ] 에러율 < 0.1%

---

## 5. 장애 복구 시나리오

### 시나리오 5.1: 네트워크 장애 대응
**목표**: 네트워크 연결이 끊어졌을 때 사용자 경험 검증

#### 테스트 케이스
1. **오프라인 모드**
   - 네트워크 연결 차단
   - 로컬 캐시 데이터 표시 확인
   - 오프라인 메시지 표시

2. **재연결 시 동기화**
   - 네트워크 복구
   - 자동 재연결 확인
   - 캐시 데이터 동기화

3. **작업 중 장애**
   - 데이터 임포트 중 네트워크 끊김
   - 진행 상태 저장 확인
   - 재연결 후 재개 또는 재시도

#### 예상 동작
- ✅ 오프라인 감지 및 메시지 표시
- ✅ 로컬 캐시 데이터 사용
- ✅ 자동 재연결
- ✅ 데이터 손실 없음

#### 검증 포인트
- [ ] 오프라인 감지
- [ ] 사용자 알림
- [ ] 캐시 활용
- [ ] 자동 재연결
- [ ] 데이터 동기화

---

### 시나리오 5.2: 잘못된 데이터 처리
**목표**: 형식이 잘못된 데이터를 업로드했을 때 처리 검증

#### 테스트 케이스
1. **잘못된 CSV 형식**
   - 헤더 없는 CSV
   - 잘못된 인코딩 (EUC-KR)
   - 빈 행 포함
   - 불완전한 행

2. **에러 메시지 표시**
   - 구체적인 에러 메시지
   - 행 번호 및 컬럼 표시
   - 수정 방법 안내

3. **부분 임포트**
   - 유효한 행만 임포트 옵션
   - 에러 행 건너뛰기
   - 임포트 결과 리포트

#### 예상 동작
- ✅ 에러 감지 및 상세 메시지
- ✅ 사용자에게 수정 방법 안내
- ✅ 부분 임포트 옵션 제공
- ✅ 에러 로그 저장

#### 검증 포인트
- [ ] 에러 감지 정확도
- [ ] 메시지 명확성
- [ ] 부분 임포트 동작
- [ ] 에러 로그 기록
- [ ] 사용자 피드백

---

## 6. 시나리오 실행 체크리스트

### 실행 전 준비
- [ ] 테스트 계정 생성 (5개)
- [ ] 샘플 데이터 준비 (CSV, 3D 모델)
- [ ] 네트워크 모니터링 도구 설정
- [ ] 성능 측정 도구 설정
- [ ] 스크린샷/동영상 녹화 준비

### 실행 중 기록
- [ ] 각 단계별 스크린샷
- [ ] 응답 시간 측정
- [ ] 에러 메시지 캡처
- [ ] 사용자 반응 기록
- [ ] 개선 아이디어 메모

### 실행 후 정리
- [ ] 테스트 결과 리포트 작성
- [ ] 발견된 버그 이슈 등록
- [ ] 성능 지표 정리
- [ ] 개선 사항 우선순위 설정
- [ ] 다음 테스트 계획 수립

---

## 7. 성공 기준

### 기능 완성도
- 모든 기본 시나리오 통과: 100%
- 고급 시나리오 통과: 80% 이상
- 통합 시나리오 통과: 70% 이상

### 성능 기준
- 페이지 로딩: < 3초
- API 응답: < 1초
- 3D 렌더링: 30 FPS 이상
- 메모리 사용: < 500MB

### 사용자 경험
- 직관적인 UI: 별도 교육 없이 사용 가능
- 명확한 에러 메시지
- 반응성 좋은 인터랙션
- 일관된 디자인

### 안정성
- 에러율: < 0.1%
- 데이터 손실: 0건
- 보안 취약점: 0건
- RLS 정책 우회: 0건
